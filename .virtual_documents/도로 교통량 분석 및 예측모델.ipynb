import warnings
warnings.filterwarnings('ignore')





import pandas as pd
file_path = "./data/train.csv"


df = pd.read_csv(file_path)
df.head()








df.shape


df.info()








# 길의 이름 별로 평균 속도 확인
df.groupby("road_name")["target"].mean()


map_data = df.groupby(['start_latitude', 'start_longitude', 'end_latitude', 'end_longitude'])['target'].mean()
map_data = map_data.reset_index()
map_data


pip install folium


import folium


map = folium.Map(location=[33.308412, 126.488029],zoom_start=10)

# 도로의 시작 위경도, 끝 위경도, 속도 정보를 받아서 지도에 뿌려줄 함수.
def to_line(x):
  # 속도에 따른 색 지정
  if x['target'] > 80: target_color="green"
  elif x['target'] > 50: target_color='blue'
  elif x['target'] > 30: target_color='orange'
  else: target_color='red'

  folium.PolyLine(
      locations=[[x['start_latitude'], x['start_longitude']], # 시작 지점 위경도
                 [x['end_latitude'], x['end_longitude']]], # 끝 지점 위경도
      color=target_color
  ).add_to(map)

map_data.apply(to_line, axis=1)
map





# 숫자 형태의 컬럼과 문자열 행태의 컬럼 분리
import numpy as np

# select_dtypes : 자료형ㅇ로 컬럼을 선택
num_columns = df.select_dtypes(include = np.number).columns.tolist()
cat_columns = df.select_dtypes(include = object).columns.tolist()

num_columns, cat_columns


# start_node_name, end_node_name은 해당 지역을 나타내는 위경도 정보와 상관관계가 높다
df[['road_name', 'start_node_name', 'end_node_name']].head()


# id값은 머신러닝에 들어가서는 안되는 데이터
df[['id', 'road_name', 'start_node_name', 'end_node_name', 'day_of_week']]








df['base_date'] = pd.to_datetime(df['base_date'], format = "%Y%m%d")
df['year'] = df['base_date'].dt.year
df['month'] = df['base_date'].dt.month
df['dayofweek'] = df['base_date'].dt.dayofweek # 숫자 형식으로 요일을 뽑아냄





df = df.drop(['id', 'road_name', 'start_node_name', 'end_node_name', 'day_of_week', 'base_date'], axis = 1)
df.head()


df.loc[df['start_turn_restricted'] == '없음', 'start_turn_restricted'] = 0
df.loc[df['start_turn_restricted'] == '있음', 'start_turn_restricted'] = 1
df.loc[df['end_turn_restricted'] == '없음', 'end_turn_restricted'] = 0
df.loc[df['end_turn_restricted'] == '있음', 'end_turn_restricted'] = 1

# 타입 강제 변경?
df['start_turn_restricted'] = df['start_turn_restricted'].astype(int)
df['end_turn_restricted'] = df['end_turn_restricted'].astype(int)

df.head()


# 모든 데이터가 숫자 타입인지 확인
df.dtypes





# Feature와 target 분리
X = df.drop("target", axis = 1)
y = df['target']


from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor # 구간 내에서 "평군"을 사용하는 방식

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size = 0.2,
    random_state = 0
)


# StandardScaling 적용
from sklearn.preprocessing import StandardScaler

std_scaler = StandardScaler()

X_train_scaled = std_scaler.fit_transform(X_train)
X_test_scaled = std_scaler.transform(X_test)


%%time

rf_clf = RandomForestRegressor(
    n_estimators = 100,
    max_depth = 5, # 과대적합 트리를 사용하지 않음! 깊이를 최대로 설정하면 훈련하는데 3시간 걸려요...
    n_jobs = -1,
    verbose = 1,
    random_state = 0
)

rf_clf.fit(X_train_scaled, y_train)


from sklearn.metrics import mean_absolute_percentage_error

predicted_train = rf_clf.predict(X_train_scaled)
predicted_test = rf_clf.predict(X_test_scaled)

print(f"{mean_absolute_percentage_error(predicted_train, y_train)}")
print(f"{mean_absolute_percentage_error(predicted_test, y_test)}")


pip install shap


import shap

explainer = shap.Explainer(rf_clf)
shap_values = explainer(X_test_scaled)
shap.summary_plot(shap_values, X_test, plot_type='bar') # permutation importance


shap.plots.beeswarm(shap_values)


# SHAP 분석을 통해 의미가 있는 Feature만 따로 뽑아서 훈련
X_train, X_test, y_train, y_test = train_test_split(
    X[['maximum_speed_limit','end_latitude','start_latitude','road_rating','start_longitude','base_hour','end_longitude','lane_count']],
    y,
    test_size=0.2,
    random_state=0)


sc = StandardScaler()
sc.fit(X_train)

X_train_std = sc.transform(X_train)
X_test_std  = sc.transform(X_test)

rf_reg = RandomForestRegressor(n_estimators=100, max_depth=5, n_jobs=-1, verbose=1, random_state=0)

rf_reg.fit(X_train_std, y_train)

predicted_train = rf_reg.predict(X_train_std)
predicted_test = rf_reg.predict(X_test_std)

print(f"{mean_absolute_percentage_error(predicted_train, y_train)}")
print(f"{mean_absolute_percentage_error(predicted_test, y_test)}")


explainer = shap.Explainer(rf_clf)
shap_values = explainer(X_test_std)
shap.summary_plot(shap_values, X_test, plot_type='bar')


# XGBoost
import xgboost

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

xgb_model = xgboost.XGBRegressor(n_estimators=100, max_depth=5)
xgb_model.fit(X_train, y_train)

xgb_predicted_train = xgb_model.predict(X_train)
xgb_predicted_test = xgb_model.predict(X_test)

print(f"{mean_absolute_percentage_error(xgb_predicted_train, y_train)}")
print(f"{mean_absolute_percentage_error(xgb_predicted_test, y_test)}")


explainer = shap.Explainer(xgb_model)
shap_values = explainer(X_test)
shap.summary_plot(shap_values, X_test, plot_type='bar')





shap.plots.beeswarm(shap_values)



